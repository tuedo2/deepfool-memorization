{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from curv_scoring import get_curv_scores_for_net\n",
    "from utils import full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetTransformDataset(Dataset):\n",
    "    def __init__(self, dataset, subset_indices, subset_transform=None, default_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (Dataset): The original dataset.\n",
    "            subset_indices (list or range): The indices for the subset to apply the transform.\n",
    "            subset_transform (callable, optional): A function/transform to apply to the subset.\n",
    "            default_transform (callable, optional): A function/transform to apply to the entire datset first.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.subset_indices = subset_indices\n",
    "        self.subset_transform = subset_transform\n",
    "        self.default_transform = default_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        if self.default_transform:\n",
    "            image = self.default_transform(image)\n",
    "\n",
    "        # Apply the transform only to the subset\n",
    "        if idx in self.subset_indices and self.subset_transform:\n",
    "            image = self.subset_transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceWithDataset: # Transform\n",
    "    def __init__(self, replace_dataset):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            replace_dataset (Dataset): The dataset to pick images from.\n",
    "        \"\"\"\n",
    "        self.replace_dataset = replace_dataset\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Replace the given image with an image from replacement dataset.\n",
    "        \"\"\"\n",
    "        # Randomly pick an index from the replacement dataset\n",
    "        img, _ = self.replace_dataset[np.random.randint(0, len(self.replace_dataset))]\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):\n",
    "\n",
    "    \"\"\"\n",
    "       :param image: Image\n",
    "       :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "       :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "       :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        # print(\"Using GPU\")\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "\n",
    "\n",
    "    f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image[None, :], requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    # fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            x.grad.zero_()\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "        fs = net.forward(x)\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    pert_image = pert_image.reshape(image.shape)\n",
    "    \n",
    "    return pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deepfool:\n",
    "    def __init__(self, net, overshoot=0.02):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            net: the net trained on original dataset\n",
    "            overshoot: The amount of overshoot in deepfool attack\n",
    "        \"\"\"\n",
    "        self.net = net\n",
    "        self.overshoot = overshoot\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Replace the given image with a perturbed image per deepfool attack.\n",
    "        \"\"\"\n",
    "        img = deepfool(img, self.net).cpu()\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist = torchvision.datasets.KMNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basenet = full_train(kmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fashion = SubsetTransformDataset(fashion, torch.arange(10), subset_transform=Deepfool(basenet, 0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-5.3560e-03, -2.5315e-02, -1.8465e-02, -3.7206e-02, -1.9193e-02,\n",
       "           -1.6945e-02, -4.3255e-03, -5.5584e-03,  8.1460e-05, -1.0137e-02,\n",
       "           -9.5216e-03, -2.8114e-02, -1.8528e-02, -3.4614e-02, -2.0056e-02,\n",
       "           -5.0703e-02, -2.5809e-02, -2.9258e-02, -8.6055e-03,  5.9933e-03,\n",
       "            5.8762e-03,  9.4791e-03,  8.7245e-03, -1.9654e-02, -1.9933e-02,\n",
       "           -2.6485e-02, -1.1971e-02, -7.9867e-03],\n",
       "          [-1.6058e-02, -3.4708e-02, -3.8753e-02, -3.3911e-02, -2.4332e-02,\n",
       "           -1.4327e-03, -2.9478e-03, -1.9791e-03, -6.1116e-03, -4.0810e-03,\n",
       "           -1.4796e-02, -1.4140e-02, -2.5086e-02, -2.4017e-02, -3.6437e-02,\n",
       "           -4.3549e-02, -3.9317e-02, -2.1442e-02, -1.0506e-02, -4.6816e-03,\n",
       "           -2.2964e-03,  6.0766e-03,  9.0182e-03, -1.9388e-02, -2.3698e-02,\n",
       "           -2.0244e-02, -1.6657e-02, -5.6432e-04],\n",
       "          [-5.5583e-03, -1.8756e-02, -9.7472e-03, -3.5094e-03,  5.2149e-03,\n",
       "            1.4557e-02,  5.9165e-03,  1.7309e-03, -1.4682e-03,  7.1379e-03,\n",
       "            1.2084e-02,  4.8112e-03,  1.2992e-02, -4.4217e-03, -2.2978e-02,\n",
       "           -4.1071e-02, -4.8519e-02, -8.7702e-03, -7.3142e-03, -7.6750e-04,\n",
       "           -1.1586e-02, -9.4202e-03, -1.7608e-02, -1.9442e-02, -2.8829e-02,\n",
       "           -5.4096e-03, -2.0668e-03,  4.4185e-04],\n",
       "          [-8.3002e-03, -1.8194e-04, -6.5269e-03,  2.7554e-02,  1.2277e-02,\n",
       "            3.5417e-02,  1.3313e-02,  3.7828e-02,  2.3278e-02,  4.5106e-02,\n",
       "            3.8509e-02,  2.2895e-02,  4.1113e-02,  4.9708e-03, -3.1282e-02,\n",
       "           -1.6197e-02,  2.3274e-01, -2.2239e-02,  6.8428e-03, -8.4376e-03,\n",
       "            3.9556e-03, -1.0272e-02, -2.8810e-02, -4.2133e-02, -3.5020e-02,\n",
       "            4.6019e-03,  7.9424e-03,  7.4878e-03],\n",
       "          [ 5.2393e-03,  1.6772e-02,  1.3110e-02,  2.4732e-02,  1.6787e-02,\n",
       "            2.5567e-02,  1.5934e-02,  4.5226e-02,  4.3120e-02,  5.7021e-02,\n",
       "            5.6609e-02,  6.8023e-02,  1.1087e-01,  6.7029e-03,  1.2343e-01,\n",
       "            4.4574e-01,  4.3297e-01,  2.3019e-01,  2.0115e-01, -3.9383e-02,\n",
       "           -2.5948e-02, -2.1349e-02, -2.4190e-02, -2.8464e-02,  5.3419e-03,\n",
       "            1.9569e-02,  3.4200e-02,  4.3127e-02],\n",
       "          [ 7.8028e-03, -3.8468e-03,  7.0476e-03, -6.1164e-03,  1.0971e-02,\n",
       "            9.2359e-03,  1.6743e-02,  3.3617e-02,  5.2499e-02,  3.8649e-02,\n",
       "            7.8422e-02,  9.6740e-02,  1.7244e-01,  2.4021e-02,  4.0233e-01,\n",
       "            7.7768e-01,  6.6908e-01,  5.2061e-01,  5.5416e-01,  4.2736e-01,\n",
       "            3.8239e-02, -2.5133e-02, -1.9767e-02, -5.3972e-03,  4.9280e-03,\n",
       "            9.1647e-02,  8.3300e-02,  2.4722e-02],\n",
       "          [-1.7445e-03, -1.7728e-02, -1.6148e-02, -3.4508e-02, -1.6518e-02,\n",
       "           -6.7866e-03,  4.9886e-04,  1.7440e-03, -3.5603e-03,  7.2681e-03,\n",
       "            8.0160e-02,  1.0871e-01,  1.0915e-01,  2.4603e-02,  6.1521e-01,\n",
       "            9.2315e-01,  8.2646e-01,  7.0215e-01,  3.9110e-01,  4.9192e-01,\n",
       "            5.2923e-01,  3.4859e-01,  2.2095e-01,  8.6475e-02,  2.9977e-01,\n",
       "            5.3167e-01,  2.9660e-01,  6.8738e-02],\n",
       "          [-3.4715e-03, -1.6100e-02, -2.1787e-02, -2.8862e-02, -1.8728e-02,\n",
       "           -8.3678e-03,  2.0842e-03, -5.4049e-03, -2.3854e-02, -6.0939e-03,\n",
       "            2.9518e-02,  9.0489e-02,  5.6932e-02,  2.9390e-01,  8.3271e-01,\n",
       "            9.0777e-01,  8.9820e-01,  8.6273e-01,  8.5073e-01,  5.4828e-01,\n",
       "            4.2895e-01,  3.9163e-01,  4.3996e-01,  5.6148e-01,  5.2106e-01,\n",
       "            2.9721e-01,  6.3900e-01,  2.6732e-01],\n",
       "          [-1.0871e-03, -4.2190e-03, -5.7311e-03, -6.1336e-03, -1.5870e-03,\n",
       "           -7.9281e-03, -7.6879e-03, -1.1716e-02, -3.8686e-02, -1.3774e-02,\n",
       "            3.5785e-02,  5.3767e-02,  5.7370e-02,  8.4744e-01,  9.6256e-01,\n",
       "            9.5420e-01,  9.9474e-01,  9.3752e-01,  8.4287e-01,  7.5642e-01,\n",
       "            7.2241e-01,  6.8891e-01,  5.9112e-01,  4.7315e-01,  4.2854e-01,\n",
       "            6.6662e-01,  8.5551e-01,  1.4380e-02],\n",
       "          [-2.7230e-03, -8.3421e-03, -1.4167e-02, -1.0534e-02, -7.1051e-03,\n",
       "           -1.5503e-02, -1.7362e-02, -1.4508e-02, -3.4179e-02, -3.1765e-02,\n",
       "            4.9063e-02,  4.2962e-02,  4.7595e-02,  7.7216e-01,  9.5689e-01,\n",
       "            8.6905e-01,  9.2544e-01,  9.2420e-01,  9.2780e-01,  8.3978e-01,\n",
       "            8.0687e-01,  7.7917e-01,  8.5143e-01,  8.4479e-01,  8.4997e-01,\n",
       "            8.8362e-01,  6.4165e-01,  2.3338e-03],\n",
       "          [ 2.0850e-03, -8.1760e-04, -4.6748e-03, -6.1672e-03, -4.4222e-03,\n",
       "           -7.7160e-03, -1.9120e-03, -5.5432e-03, -6.6533e-03,  2.1547e-02,\n",
       "            5.3720e-02,  2.8809e-02,  1.3356e-01,  8.7438e-01,  9.8290e-01,\n",
       "            8.9081e-01,  8.4833e-01,  7.7263e-01,  7.0719e-01,  8.1213e-01,\n",
       "            7.5748e-01,  7.6273e-01,  7.8659e-01,  8.6325e-01,  8.2567e-01,\n",
       "            8.6781e-01,  7.4872e-01,  6.3689e-03],\n",
       "          [ 5.5187e-03, -2.0010e-03, -2.1131e-03, -4.8421e-03, -4.3880e-03,\n",
       "           -2.6567e-03, -2.8646e-03,  5.2970e-03, -4.1841e-02, -4.1532e-03,\n",
       "            3.4351e-02,  4.1606e-02,  1.4350e-01,  9.4428e-01,  9.1578e-01,\n",
       "            8.5770e-01,  8.6963e-01,  7.5598e-01,  6.6918e-01,  9.3935e-01,\n",
       "            8.4712e-01,  8.5921e-01,  8.6868e-01,  8.1330e-01,  8.4241e-01,\n",
       "            7.1134e-01,  7.6293e-01,  1.7656e-01],\n",
       "          [ 6.3622e-03, -1.9322e-03, -1.2875e-03, -9.7576e-03, -4.0769e-04,\n",
       "           -2.5842e-02, -1.7718e-02, -3.3259e-02, -7.1678e-02, -1.5589e-02,\n",
       "            3.3889e-02,  6.9630e-02,  5.3985e-01,  1.0798e+00,  9.0128e-01,\n",
       "            8.8047e-01,  8.5932e-01,  8.3506e-01,  8.2297e-01,  9.3848e-01,\n",
       "            8.7056e-01,  8.4639e-01,  8.5274e-01,  8.0161e-01,  8.9120e-01,\n",
       "            3.8772e-01,  6.0513e-01,  1.9002e-01],\n",
       "          [ 7.4603e-03, -1.2496e-02, -2.9844e-02, -2.8520e-02, -3.8894e-02,\n",
       "           -3.5800e-02, -2.0513e-02, -3.3894e-02, -4.6905e-02, -3.1134e-02,\n",
       "            4.1161e-02,  4.6932e-02,  3.1277e-01,  9.7179e-01,  8.7359e-01,\n",
       "            9.2199e-01,  9.4125e-01,  1.0700e+00,  9.9795e-01,  8.8398e-01,\n",
       "            9.1451e-01,  8.8925e-01,  9.0114e-01,  7.9318e-01,  7.8159e-01,\n",
       "            7.1896e-01,  3.0919e-01, -1.4596e-02],\n",
       "          [-1.7217e-03, -1.1456e-02, -5.2363e-02, -1.9417e-02, -4.7292e-02,\n",
       "           -1.7390e-02, -5.5573e-03,  2.0607e-02,  6.8059e-02,  7.6075e-02,\n",
       "            1.9085e-01,  1.0840e-01,  1.0555e+00,  9.3727e-01,  8.0448e-01,\n",
       "            9.0166e-01,  9.4850e-01,  9.6598e-01,  9.9781e-01,  9.6916e-01,\n",
       "            9.1069e-01,  8.9719e-01,  8.5967e-01,  7.6672e-01,  7.7359e-01,\n",
       "            9.1865e-01,  2.9561e-01, -7.9007e-04],\n",
       "          [-3.5009e-03, -1.7486e-02, -6.1201e-02, -4.6841e-02, -6.4568e-02,\n",
       "           -3.7576e-02,  2.2247e-02,  6.1739e-02,  1.2574e-01,  3.4375e-01,\n",
       "            7.6546e-01,  8.5808e-01,  8.9837e-01,  7.5026e-01,  7.4121e-01,\n",
       "            8.5459e-01,  9.6763e-01,  8.8426e-01,  9.4952e-01,  1.0117e+00,\n",
       "            9.3399e-01,  8.8911e-01,  7.9213e-01,  7.6338e-01,  8.0249e-01,\n",
       "            9.1515e-01,  6.3922e-01,  1.0233e-02],\n",
       "          [-1.6741e-02, -2.5169e-02, -9.0973e-02, -8.2074e-02, -6.2234e-04,\n",
       "            1.4405e-01,  4.2229e-01,  5.1253e-01,  9.6428e-01,  1.1014e+00,\n",
       "            1.0471e+00,  9.4572e-01,  8.4007e-01,  8.1263e-01,  7.2168e-01,\n",
       "            7.8224e-01,  8.4115e-01,  9.7072e-01,  1.0602e+00,  1.0708e+00,\n",
       "            6.9738e-01,  7.4110e-01,  8.8751e-01,  8.8605e-01,  8.8830e-01,\n",
       "            9.4727e-01,  8.7216e-01,  4.9454e-02],\n",
       "          [-1.8988e-02,  1.8530e-01,  6.4626e-01,  7.3798e-01,  8.2724e-01,\n",
       "            9.0043e-01,  9.7107e-01,  8.7911e-01,  9.4906e-01,  9.3385e-01,\n",
       "            8.6591e-01,  7.5819e-01,  6.8499e-01,  5.5397e-01,  8.9993e-01,\n",
       "            7.3587e-01,  8.0683e-01,  9.0803e-01,  1.0821e+00,  1.0461e+00,\n",
       "            8.3553e-01,  8.6603e-01,  8.4221e-01,  8.2932e-01,  8.8434e-01,\n",
       "            9.8795e-01,  1.0588e+00,  5.4168e-02],\n",
       "          [-3.8113e-04,  7.4431e-01,  8.0380e-01,  7.9553e-01,  8.3712e-01,\n",
       "            8.3786e-01,  9.2186e-01,  9.4480e-01,  9.1493e-01,  8.9545e-01,\n",
       "            8.1300e-01,  7.9033e-01,  8.7551e-01,  2.9260e-01,  5.8365e-01,\n",
       "            9.9846e-01,  8.9571e-01,  8.5483e-01,  7.0393e-01,  5.8818e-01,\n",
       "            6.9634e-01,  7.7898e-01,  7.8458e-01,  8.0723e-01,  8.6283e-01,\n",
       "            9.4430e-01,  9.6109e-01,  3.8624e-02],\n",
       "          [ 3.7981e-01,  9.0862e-01,  7.8096e-01,  8.1925e-01,  8.7359e-01,\n",
       "            9.0232e-01,  9.4422e-01,  9.4908e-01,  1.0108e+00,  8.2429e-01,\n",
       "            7.3049e-01,  7.7005e-01,  8.1841e-01,  9.3667e-01,  2.5439e-01,\n",
       "            3.1637e-01,  3.9805e-01,  4.2881e-01,  5.8321e-01,  7.3410e-01,\n",
       "            7.5198e-01,  7.7902e-01,  8.2424e-01,  8.4859e-01,  8.2237e-01,\n",
       "            8.2843e-01,  8.4939e-01,  1.2884e-01],\n",
       "          [ 2.9471e-01,  8.0217e-01,  8.3226e-01,  8.0206e-01,  7.5556e-01,\n",
       "            8.0855e-01,  8.4069e-01,  9.3042e-01,  8.7070e-01,  7.1813e-01,\n",
       "            7.8904e-01,  8.0727e-01,  7.5652e-01,  8.6040e-01,  9.5677e-01,\n",
       "            7.7440e-01,  8.7017e-01,  8.5422e-01,  8.3810e-01,  7.4782e-01,\n",
       "            7.8521e-01,  7.9141e-01,  7.8873e-01,  8.4117e-01,  8.0034e-01,\n",
       "            7.6685e-01,  8.3704e-01,  2.5844e-01],\n",
       "          [ 2.3845e-01,  8.4884e-01,  7.8329e-01,  7.8629e-01,  8.5171e-01,\n",
       "            7.7254e-01,  7.2400e-01,  7.9407e-01,  7.9647e-01,  7.5101e-01,\n",
       "            8.0336e-01,  8.3628e-01,  8.7234e-01,  8.8040e-01,  8.5740e-01,\n",
       "            8.9747e-01,  8.6639e-01,  7.6899e-01,  7.1300e-01,  6.8608e-01,\n",
       "            6.7592e-01,  7.0074e-01,  6.8323e-01,  6.6345e-01,  6.1865e-01,\n",
       "            6.2038e-01,  6.7010e-01,  4.3753e-01],\n",
       "          [ 6.1069e-02,  5.4545e-01,  9.4138e-01,  7.7622e-01,  6.9361e-01,\n",
       "            6.5764e-01,  6.8823e-01,  7.5195e-01,  8.0021e-01,  8.3472e-01,\n",
       "            8.8472e-01,  8.0072e-01,  8.1847e-01,  7.7171e-01,  7.7994e-01,\n",
       "            7.3816e-01,  7.4431e-01,  6.8170e-01,  6.7107e-01,  6.7820e-01,\n",
       "            7.3079e-01,  7.3956e-01,  6.8936e-01,  6.0808e-01,  6.0369e-01,\n",
       "            5.9029e-01,  7.1374e-01,  3.3449e-01],\n",
       "          [ 7.6839e-02,  1.0708e-01,  3.5775e-01,  7.6434e-01,  7.7181e-01,\n",
       "            7.0071e-01,  5.6927e-01,  6.1184e-01,  6.2780e-01,  7.4640e-01,\n",
       "            8.1110e-01,  7.2773e-01,  6.7807e-01,  6.0690e-01,  6.8142e-01,\n",
       "            6.9937e-01,  7.5936e-01,  7.8748e-01,  8.0557e-01,  7.4479e-01,\n",
       "            7.9104e-01,  7.2866e-01,  7.3490e-01,  7.3891e-01,  6.9057e-01,\n",
       "            6.7578e-01,  5.8324e-01, -5.3605e-03],\n",
       "          [ 4.3446e-02,  4.2363e-02,  1.0112e-02, -1.9140e-02,  1.9089e-01,\n",
       "            7.2045e-01,  7.3959e-01,  8.4327e-01,  8.7111e-01,  1.0074e+00,\n",
       "            1.0783e+00,  9.4934e-01,  8.5773e-01,  7.6095e-01,  7.9454e-01,\n",
       "            7.2562e-01,  7.2326e-01,  6.8862e-01,  7.2174e-01,  7.2161e-01,\n",
       "            7.1084e-01,  6.7174e-01,  6.3763e-01,  6.2843e-01,  3.5208e-01,\n",
       "            1.7148e-01, -2.6087e-02, -1.3995e-02],\n",
       "          [ 3.1950e-02,  3.4369e-02, -7.0165e-03, -4.9406e-02, -7.3691e-02,\n",
       "           -1.0931e-01, -9.4657e-02,  6.0414e-02,  2.0564e-01,  2.0697e-01,\n",
       "            3.8048e-01,  1.8270e-01,  1.0670e-01, -7.6457e-02, -4.6391e-02,\n",
       "           -4.2829e-02, -4.1368e-02, -8.9671e-03,  8.6114e-03, -1.8216e-03,\n",
       "           -2.9154e-02, -3.1317e-02, -3.1111e-02, -3.3454e-02, -5.5207e-02,\n",
       "           -6.0932e-02, -4.0915e-02, -8.2002e-03],\n",
       "          [ 5.1316e-03, -6.7539e-03, -1.2570e-02, -5.8476e-02, -4.3204e-02,\n",
       "           -5.4091e-02, -4.7093e-02, -5.3998e-02, -3.0540e-02,  3.3815e-02,\n",
       "            3.6600e-02,  4.1558e-03, -3.2062e-03, -4.7015e-02, -2.5403e-02,\n",
       "           -3.6466e-02, -1.8200e-02, -5.1219e-03, -6.2625e-03, -2.0122e-02,\n",
       "           -1.8877e-02, -1.9689e-02, -1.5513e-02, -2.8039e-02, -8.3387e-03,\n",
       "           -2.6997e-02, -1.5197e-02, -2.3374e-03],\n",
       "          [ 3.3918e-03, -8.3607e-03, -1.6718e-02, -4.0718e-02, -4.9680e-02,\n",
       "           -2.7549e-02, -4.1105e-02, -4.9798e-02, -1.1062e-02,  3.4657e-02,\n",
       "            3.3829e-02, -3.8679e-03, -1.9006e-02, -3.0397e-02, -3.1086e-02,\n",
       "           -1.8327e-02, -1.4790e-02, -1.6943e-03,  1.2156e-03, -1.8564e-02,\n",
       "           -1.5034e-02, -1.1462e-02, -1.0799e-02, -9.4148e-03, -8.8188e-03,\n",
       "           -1.8584e-02, -7.2014e-03, -1.1133e-04]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fashion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_idx(dset, idx):\n",
    "    img, label = dset[idx]\n",
    "    img_np = img.squeeze().numpy()\n",
    "    plt.imshow(img_np, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_idx(fashion, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_02/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_04/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_10/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_scores_for_net(train, net):\n",
    "    total = 0\n",
    "    scores = torch.zeros(len(train))\n",
    "    loader = torch.utils.data.DataLoader(dataset=train, batch_size=512, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            start_idx = total\n",
    "            stop_idx = total + len(targets)\n",
    "            idxs = [j for j in range(start_idx, stop_idx)]\n",
    "            total = stop_idx\n",
    "\n",
    "            logits = net(inputs)\n",
    "            softmax_probs = F.softmax(logits, dim=1)\n",
    "            max_softmax, _ = torch.max(softmax_probs, dim=1)\n",
    "            \n",
    "            scores[idxs] = max_softmax.cpu()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_02_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_10_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_100_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_500_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_04_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_10_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import full_train_CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_02/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_04/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    subset_idx = torch.randperm(len(cifar10))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_10/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=10, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=100, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=500, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=1000, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_02_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=10, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=100, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=500, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=1000, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_04_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=10, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_10_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=100, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_100_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=500, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_500_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=1000, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/deepfool_1000_overshoot_10_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_cifar10 = torchvision.datasets.FakeData(size=50000, image_size=(3, 32, 32), transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    subset_idx = torch.randperm(len(cifar10))[:10]\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_10/run_{i+1}', **score_dict)\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=10, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_10_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    subset_idx = torch.randperm(len(cifar10))[:100]\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_100/run_{i+1}', **score_dict)\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=100, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_100_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    subset_idx = torch.randperm(len(cifar10))[:500]\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_500/run_{i+1}', **score_dict)\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=500, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_500_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    subset_idx = torch.randperm(len(cifar10))[:1000]\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_1000/run_{i+1}', **score_dict)\n",
    "    basenet = full_train_CIFAR10(cifar10)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(cifar10, basenet), k=1000, largest=False)\n",
    "    random_dset = SubsetTransformDataset(cifar10, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(fake_cifar10))\n",
    "    net = full_train_CIFAR10(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'cifar_curv_scores/random_1000_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48751, 30814, 22048, 49987, 19937,  2943,  7050, 30763, 48597, 41209])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(50000)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
