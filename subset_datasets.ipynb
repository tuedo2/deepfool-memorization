{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from curv_scoring import get_curv_scores_for_net\n",
    "from utils import full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetTransformDataset(Dataset):\n",
    "    def __init__(self, dataset, subset_indices, subset_transform=None, default_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (Dataset): The original dataset.\n",
    "            subset_indices (list or range): The indices for the subset to apply the transform.\n",
    "            subset_transform (callable, optional): A function/transform to apply to the subset.\n",
    "            default_transform (callable, optional): A function/transform to apply to the entire datset first.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.subset_indices = subset_indices\n",
    "        self.subset_transform = subset_transform\n",
    "        self.default_transform = default_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        if self.default_transform:\n",
    "            image = self.default_transform(image)\n",
    "\n",
    "        # Apply the transform only to the subset\n",
    "        if idx in self.subset_indices and self.subset_transform:\n",
    "            image = self.subset_transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceWithDataset: # Transform\n",
    "    def __init__(self, replace_dataset):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            replace_dataset (Dataset): The dataset to pick images from.\n",
    "        \"\"\"\n",
    "        self.replace_dataset = replace_dataset\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Replace the given image with an image from replacement dataset.\n",
    "        \"\"\"\n",
    "        # Randomly pick an index from the replacement dataset\n",
    "        img, _ = self.replace_dataset[np.random.randint(0, len(self.replace_dataset))]\n",
    "        \n",
    "        # Resize if necessary (FashionMNIST is 28x28, make sure EMNIST image matches)\n",
    "        if img.shape[1] != 28 or img.shape[2] != 28:\n",
    "            img = transforms.Resize((28, 28))(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):\n",
    "\n",
    "    \"\"\"\n",
    "       :param image: Image\n",
    "       :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "       :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "       :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        # print(\"Using GPU\")\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "\n",
    "\n",
    "    f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image[None, :], requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    # fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            x.grad.zero_()\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "        fs = net.forward(x)\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    pert_image = pert_image.reshape(image.shape)\n",
    "    \n",
    "    return pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deepfool:\n",
    "    def __init__(self, net, overshoot=0.02):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            net: the net trained on original dataset\n",
    "            overshoot: The amount of overshoot in deepfool attack\n",
    "        \"\"\"\n",
    "        self.net = net\n",
    "        self.overshoot = overshoot\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Replace the given image with a perturbed image per deepfool attack.\n",
    "        \"\"\"\n",
    "        img = deepfool(img, self.net).cpu()\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist = torchvision.datasets.KMNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fashion = SubsetTransformDataset(fashion, torch.arange(1000), subset_transform=ReplaceWithDataset(kmnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_idx(dset, idx):\n",
    "    img, label = dset[idx]\n",
    "    img_np = img.squeeze().numpy()\n",
    "    plt.imshow(img_np, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUvklEQVR4nO3dfazWdd0H8M954OFACAoeKttSpsxwtjkZMmcTqUWkW1qOra0R1XrEcixztkRwrbUenNZo5ZaBxuZWhkattDl0syVPQ21gDCEqEOVZFIHzeN1/dPfZzQ3p+X6FiwO+Xv95cb35/fhd13Xe57cDb1sajUYjACAiWk/1CQAweCgFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBc5I//jHP6KlpSV++MMfnrDf88knn4yWlpZ48sknT9jvCYONUmDQWLJkSbS0tMTatWtP9amcNI8//nhcc801MW7cuBgzZkxMmTIlfvnLX57q04KkFKBJli9fHh/+8Ieju7s7Fi5cGN/5zneio6MjZs+eHXffffepPj2IiIj2U30C8HaxaNGieNe73hUrVqyIYcOGRUTEF7/4xbj44otjyZIlMW/evFN8huBOgdNMd3d33HHHHXH55ZfH6NGjY+TIkfGBD3wgnnjiif+aufvuu+O9731vdHR0xNVXXx3r168/5jkbN26MG2+8Mc4555wYPnx4TJ48OZYvX/6m53Po0KHYuHFj7Nmz502f++qrr8bZZ5+dhRAR0d7eHuPGjYuOjo43zUMzKAVOK6+++mr8/Oc/j2nTpsX3vve9WLhwYezevTtmzJgRzz777DHPf+CBB+LHP/5xzJ07N775zW/G+vXrY/r06bFz5858zoYNG2Lq1Knxt7/9LW677ba46667YuTIkXH99dfHww8//Ibns3r16njf+94XixYtetNznzZtWmzYsCHmz58fmzdvji1btsS3v/3tWLt2bdx6663F1wJOigYMEosXL25ERGPNmjX/9Tm9vb2Nrq6uox7bv39/Y/z48Y3Pfvaz+djWrVsbEdHo6OhobN++PR9ftWpVIyIa8+bNy8c++MEPNi699NLGkSNH8rH+/v7GlVde2bjooovysSeeeKIREY0nnnjimMcWLFjwpn++gwcPNmbNmtVoaWlpREQjIhojRoxoPPLII2+ahWZxp8Bppa2tLYYOHRoREf39/bFv377o7e2NyZMnx7p16455/vXXXx/nnXde/veUKVPiiiuuiD/84Q8REbFv375YsWJFzJo1K1577bXYs2dP7NmzJ/bu3RszZsyIF154IV588cX/ej7Tpk2LRqMRCxcufNNzHzZsWEycODFuvPHGePDBB2Pp0qUxefLk+NSnPhUrV64svBJwcvhBM6ed+++/P+66667YuHFj9PT05OMXXHDBMc+96KKLjnls4sSJ8atf/SoiIjZv3hyNRiPmz58f8+fPP+7xdu3adVSx1Lrpppti5cqVsW7dumht/ff3Y7NmzYpLLrkkbr755li1atVbPga8VUqB08rSpUtjzpw5cf3118c3vvGN6OzsjLa2tvjud78bW7ZsKf79+vv7IyLilltuiRkzZhz3ORdeeOFbOueIf/+A/L777otbb701CyEiYsiQITFz5sxYtGhRdHd3510QnCpKgdPKQw89FBMmTIhly5ZFS0tLPr5gwYLjPv+FF1445rFNmzbF+eefHxEREyZMiIh/f3H+0Ic+dOJP+H/t3bs3ent7o6+v75hf6+npif7+/uP+GjSbnylwWmlra4uIiEajkY+tWrUqnn766eM+/5FHHjnqZwKrV6+OVatWxcyZMyMiorOzM6ZNmxb33ntvvPTSS8fkd+/e/YbnM9C/ktrZ2RljxoyJhx9+OLq7u/PxgwcPxu9+97u4+OKL/bVUBgV3Cgw6v/jFL+LRRx895vGbb745rrvuuli2bFnccMMNce2118bWrVvjZz/7WUyaNCkOHjx4TObCCy+Mq666Kr785S9HV1dX3HPPPTF27Nij/groT37yk7jqqqvi0ksvjc9//vMxYcKE2LlzZzz99NOxffv2eO655/7rua5evTquueaaWLBgwRv+sLmtrS1uueWWuP3222Pq1Kkxe/bs6Ovri/vuuy+2b98eS5cuLbtIcJIoBQadn/70p8d9fM6cOTFnzpx4+eWX4957743HHnssJk2aFEuXLo1f//rXxx2qmz17drS2tsY999wTu3btiilTpuS/LP6PSZMmxdq1a+POO++MJUuWxN69e6OzszMuu+yyuOOOO07Yn+tb3/pWXHDBBfGjH/0o7rzzzujq6or3v//98dBDD8UnPvGJE3YceCtaGv/3PhyAtzU/UwAgKQUAklIAICkFAJJSACApBQDSgP+dwv+dFODMUvPaNvNvMp9zzjnFmU9+8pPFmXe84x3FmVdeeaU488ADDxRnIiIOHz5clYP/GMjn1p0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkAb8/2g2iMdb9bnPfa4qN3Xq1OLM888/X5xZs2ZNcebKK68szlxxxRXFmYiIlStXFmd+8IMfVB2rVFtbW3Gmr6/vJJwJb8QgHgBFlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgDJIN4ZpuZ1GuBb4Chf+9rXijPvfve7izMREbfddltV7kzz4IMPFmeOHDlSnPnMZz5TnKnR2lr3PWl/f/8JPpO3D4N4ABRRCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECyklqoWSukQ4cOLc5ERHR3dxdnPvKRjxRnrr322uLMV7/61eJMrSFDhhRnenp6ijM1S5/NXPlctmxZcWblypXFme9///vFmZrXKKLudeLfrKQCUEQpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkAziFaq5Du3t7cWZZo5+1YymzZo1qzjT29tbnImou361xyJi7dq1xZk5c+YUZ9avX1+cifB+eCsM4gFQRCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQypel3uYGuB94lLa2tuJM7SDe/PnzizN//etfizM1A2MdHR3FmYiIw4cPV+XONK2t5d/D9ff3F2cWL15cnLnpppuKM1/60peKMxF114GBc3UBSEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGA1NIY4MJbS0vLyT4XToBHH320OHPDDTcUZ2pG6trb6/YXa8b3zkTNGsSrsWLFiuLM9OnTT8KZHN9gvnbNNJAv9+4UAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgFS3UDYI1Qz2DXAL8CjNGtaaOXNmcSYiYseOHcWZmnG7Gs0ctmvW+6GZat5HNSOENa/T1q1bizMf+9jHijMREb/97W+LMzXvhzPxPTQQ7hQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASINuJbVmhTQioq2trThTswZZs1RZ48Ybb6zKPfXUUyf4TI6vWWuxvDU1S581Nm/eXJyZPn161bFqVlL7+vqqjvV25E4BgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASINuEK92NO1MG1v76Ec/WpX74x//eILP5MRp1jhbRESj0WjasQazmtHHGtu2bSvOfOELX6g61oIFC4ozr7zySnFm2LBhxZna4b2a3Ml6j7tTACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFANKgG8Q7E02cOLE48+yzz1Ydq3aQq1QzBwhbW8u/d6kZ36sZGGvWcd5Krhne8573FGfa2tqqjnXxxRcXZ1auXFmc6erqKs6cCdwpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAKmlMcCVrZrhrxq/+c1vqnKXXHJJcWbnzp3FmXHjxhVn/vWvfxVn9uzZU5yJiGhvL984/NOf/lScefjhh4szr7zySnGG08PcuXOLMxMmTKg6VrM+TzWjj2PHji3ORET85S9/Kc6sW7euODOQL/fuFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIg24l9bHHHqvKXXjhhcWZ3t7e4kxXV1dx5siRI8WZmjXWiIhdu3YVZ4YOHVqcqbl2ra1134Pcf//9xZlly5YVZw4cOFCcGTJkSHGmZtE3IuK6665ryrEmTZpUnNm7d29xZvz48cWZiIj9+/cXZ2re4x0dHcWZs88+uzgTEbF8+fLizOzZs4szVlIBKKIUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASO2n+gT+v/7+/qrcAHf9jnLw4MHiTE9PT3GmZkRv06ZNxZmIuoG2ffv2FWcOHz5cnDn33HOLMxERX/nKV4ozc+fOLc68/vrrxZnakb8aNe/XQ4cOFWdefPHF4kyNmvHGiIjhw4cXZ/75z38WZ0aMGFGcqXmNIuo+TyeLOwUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgDbpBvGHDhlXlRo0aVZzZv39/cWbo0KHFmbPOOqs4Uzu0tnv37uJMd3d3caatra04s2XLluJMRMTevXuLMzXXvOY9VDM418zxs76+vuLMkSNHijMdHR3FmZrPUkTEO9/5zuJMzZ+pZmSzvb3uS2rN16KTxZ0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkAbdIN7rr79elasZdevv7y/O1Ixk7dixozjT09NTnKnN1YzH1QziDRkypDhT6+DBg8WZ0aNHF2c6OzuLM88//3xxJqJubK3mmteM/O3Zs6c4U/Meioj4+9//XpwZMWJEcWbr1q3Fmcsvv7w4ExGxbdu2qtzJ4E4BgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASINuEK9myCwiYvjw4cWZmnG7oUOHFmfGjh1bnGltrevrmpG/3t7e4kzNdTh8+HBxJiKiq6urONPS0lKc2bdvX3HmwIEDxZnaIbhRo0YVZ2oG8UaOHFmcGTNmTHGm5nWNqPvcjhs3rjhT8xmcPHlycSYiYt68eVW5k8GdAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBp0K2k1qxORkSMHj26OFOzrFqzDtrT01OcqV2QrFlJrVmDHDZsWHGm5tpF1K24HjlypDhTc37NykREjBgxojhTsxZbc+3a28u/lNSssdbmaj5PNdehu7u7OBNR9zXiZHGnAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKAKRBN4i3Y8eOqtyQIUOKM21tbcWZmoGxmkzNwFhERF9fX1WuVM3wXs31jqi7FjWDfTWZmte25r1ae6yaobWa49S8ts28DgcPHizO1Fy7TZs2FWciIjZu3FiVOxncKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBp0A3i7d2791Sfwhvq7e1tynFqx8JaW8t7vmbcrkbNkFlE3SBeTaajo6M4UzNA2KzrHVE3VFczDFg7dlij5rNR87kYPnx4ceass84qzkREHDhwoCp3MrhTACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFANKgG8Rbv359VW7nzp0n+EyOr2aMq6enpzjTzIGxmmPVZGrG45pp6NChxZmagcTaUcWakb9Go1GcadZgX+1xat5HI0eOLM5s27atOLNly5bizGDjTgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIg24Q75lnnqnKjR8/vjjz6quvFmdqhuBqRslqB/EG82haa2vd9yA1x6q5DjWZmnG2muG92lzNGGONmvdQ7fuhq6urOFMzZHnuuecWZ5577rnizGDjTgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGANOhWUmuWSyMiXnrppeJMR0dHcea1114rztQuntaoWRRtaWkpztQsXNYsaUbULVzWLIqeiWuxzXydmqXmta25duedd15x5ve//31xZrBxpwBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgCkQTeIV2vNmjXFmalTpxZnagbGmjXOFhFx+PDhqlypmuvQ19dXdaya69feXv7W7unpKc7UXIeaAcKIuutXcx1qxuNq1F6H3t7epmSGDx9enHnqqaeKM4ONOwUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgtTQGuLxWO17VLCNGjCjObNiwoThTM1RXMzBWO2xXM9BWkxkyZEhTjhNRN+pWo1mDeLVjhzVqjlUzvNfM61Dztaitra0488wzzxRnPv7xjxdnmmkg19ydAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCaszTWBIcOHSrOLF68uDjz9a9/vTizdevW4kzteFzNWFjNMFlvb29xplbNoGCN7u7u4kyzBhJr1ZxfzdhhzXFqRzZr3ntjxowpztx+++3FmVrN+twOhDsFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAFJLY4BTe7WLhmeaxx9/vDhz2WWXFWe6urqKMxERbW1txZnOzs6qY8F/vPzyy8WZ2rXYESNGFGeWL19enPn0pz9dnBnsBvLl3p0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkAziNcHVV19dnDn//POrjjVq1KjiTF9fX3Gmp6enOFMz1hdR996rydRch5pRt5rj1Brgx/soNWOMhw8fLs7Uvh927txZnPnzn/9cdawzjUE8AIooBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAFL7QJ9YM6wFwOnFnQIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAOl/AITN7KAqo/ZiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_idx(fashion, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_02/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_02/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_04/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_04/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:10].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:100].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:500].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_10/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    subset_idx = torch.randperm(len(fashion))[:1000].numpy()\n",
    "    random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(random_dset)\n",
    "    scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_10/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_scores_for_net(train, net):\n",
    "    total = 0\n",
    "    scores = torch.zeros(len(train))\n",
    "    loader = torch.utils.data.DataLoader(dataset=train, batch_size=512, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            start_idx = total\n",
    "            stop_idx = total + len(targets)\n",
    "            idxs = [j for j in range(start_idx, stop_idx)]\n",
    "            total = stop_idx\n",
    "\n",
    "            logits = net(inputs)\n",
    "            softmax_probs = F.softmax(logits, dim=1)\n",
    "            max_softmax, _ = torch.max(softmax_probs, dim=1)\n",
    "            \n",
    "            scores[idxs] = max_softmax.cpu()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_02_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.02))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_02_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_10_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_100_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "# for i in range(5):\n",
    "#     print(f'Saving scores for run {i+1}...')\n",
    "#     basenet = full_train(fashion)\n",
    "#     _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "#     # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "#     # net = full_train(random_dset)\n",
    "#     # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "#     # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "#     fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "#     net = full_train(fool_dset)\n",
    "#     scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "#     score_dict = dict(subset=subset_idx, scores=scores)\n",
    "#     np.savez(f'curv_scores/deepfool_500_overshoot_04_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.04))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_04_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n",
      "Saving scores for run 1...\n",
      "Saving scores for run 2...\n",
      "Saving scores for run 3...\n",
      "Saving scores for run 4...\n",
      "Saving scores for run 5...\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=10, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_10_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=100, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_100_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=500, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_500_overshoot_10_attack/run_{i+1}', **score_dict)\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Saving scores for run {i+1}...')\n",
    "    basenet = full_train(fashion)\n",
    "    _, subset_idx = torch.topk(get_boundary_scores_for_net(fashion, basenet), k=1000, largest=False)\n",
    "    # random_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=ReplaceWithDataset(kmnist))\n",
    "    # net = full_train(random_dset)\n",
    "    # scores = get_curv_scores_for_net(random_dset, net).cpu().numpy()\n",
    "    # score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    # np.savez(f'curv_scores/random_10_attack/run_{i+1}', **score_dict)\n",
    "    fool_dset = SubsetTransformDataset(fashion, subset_indices=subset_idx, subset_transform=Deepfool(basenet, overshoot=0.10))\n",
    "    net = full_train(fool_dset)\n",
    "    scores = get_curv_scores_for_net(fool_dset, net).cpu().numpy()\n",
    "    score_dict = dict(subset=subset_idx, scores=scores)\n",
    "    np.savez(f'curv_scores/deepfool_1000_overshoot_10_attack/run_{i+1}', **score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
